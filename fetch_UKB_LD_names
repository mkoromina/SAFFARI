import pandas as pd

SS = config["summary_stats_prefix"]  #then daner_bip_pgc3
mode = config["mode"]
# functional_finemapping = config["functional_finemapping"]
##parallelize for multiple datasets SS="(suicide_gwas|daner_bip_pgc3)"

gwas_df_path = "/sc/arion/projects/ad-omics/data/references/GWAS/GWAS-QTL_data_dictionary_GWAS.tsv"
gwas_df = pd.read_csv(gwas_df_path, sep = '\t')

top_loci_file = {}

for ss in SS:
	if (gwas_df['finemapping_top_path'][gwas_df['dataset'] == ss].isnull().values.any()):
		top_loci_file[ss] = gwas_df_path
	else: 
		top_loci_file[ss] = gwas_df['finemapping_top_path'][gwas_df['dataset'] == ss].values[0]
		
print(top_loci_file)

rule all:
    input: expand("resources/{ss}_loci_ranges.tsv", ss = SS)

rule import_finemap_loci:
	input: lambda wildcards: top_loci_file[wildcards.ss]
	output: expand("resources/{{ss}}_loci_ranges.tsv", ss = SS)
	conda: "envs/r.yaml"
	resources: mem_mb = 10000
	script: "scripts/UKBiobank_LD.R"