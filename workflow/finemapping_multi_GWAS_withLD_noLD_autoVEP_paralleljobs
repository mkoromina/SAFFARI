# This snakefile can be run on an LSF cluster using a conda environment with snakemake installed. This can be done using either a configuration profile or from the command line.
# An example of how to run this snakefile from the command line is shown below:
# snakemake --snakefile <NAME_OF_THIS_FILE> --executor lsf --default-resources mem_mb=16000 runtime=480 lsf_project=<PROJECT_NAME> lsf_queue=<QUEUE_NAME> --jobs 250 --latency-wait 3600 --configfile <PATH_TO_CONFIG_FILE> --use-conda

# This will run the snakefile for each GWAS specified in the config file by submitting every occurance of each rule as a separate job to LSF (in parallel whenever possible).
# Logs from each job will be stored in the logs directory as specified under the "resources:" section of each rule.

# You could even use a wrapper script to submit the initial snakemake call to the cluster as a job itself. An example of a wrapper script is shown below:

#     #!/bin/bash
#     #BSUB -J SAFFARI_snakemake_launcher
#     #BSUB -P <PROJECT_NAME>
#     #BSUB -q <QUEUE_NAME>
#     #BSUB -n 1
#     #BSUB -W 24:00
#     #BSUB -R "rusage[mem=32000]"
#     #BSUB -o logs/SAFFARI_snakemake_launcher_%J.out
#     #BSUB -e logs/SAFFARI_snakemake_launcher_%J.err
#     #BSUB -L /bin/bash
#
#     source ~/.bashrc
#
#     conda activate <PATH_TO_CONDA_ENV_WITH_SNAKEMAKE_INSTALLED>
#
#     cd <PATH_TO_YOUR_DIRECTORY>
#
#     snakemake --snakefile <NAME_OF_THIS_FILE> --executor lsf --default-resources mem_mb=16000 runtime=480 lsf_project=<PROJECT_NAME> lsf_queue=<QUEUE_NAME> --jobs 250 --latency-wait 3600 --configfile <PATH_TO_CONFIG_FILE> --use-conda



# If you just want to run the snakefile without submitting any jobs to the cluster, you can simply use the following command:
# snakemake --snakefile <NAME_OF_THIS_FILE> --configfile <PATH_TO_CONFIG_FILE> --cores <NUMBER_OF_CORES> --use-conda


# This snakefile runs functional and statistical finemapping using both susie and finemap both with LD and without LD.
# This can be altered by changing the {LD} and {method} wildcards in the rule all.
# This analysis is performed for each GWAS specified in the config file.

# This snakefile also automatically runs Ensembl Variant Effect Predictor (VEP) on the finemapping results for each GWAS specified in the config file.



import pandas as pd
import os

os.makedirs("logs", exist_ok = True)

SS = config["summary_stats_prefix"]
CHR = list(range(1,23))

snp_tables = {}
full_sumstats = {}
sample_size = {}

for i, ss in enumerate(SS):
    tsv_file = config["top_loci_file"][i]
    snp_tables[ss] = pd.read_table(tsv_file, sep='\t', dtype = str).set_index("SNP", drop = False)
    full_sumstats[ss] = config["full_sumstats"][i]
    sample_size[ss] = config["N"][i]

print(snp_tables)


rule all:
    input:
        expand("output/{ss}_neff.munged.parquet", ss = SS),
        expand("output/{ss}/priors/{ss}_l2-ldsc.{chr}.snpvar_ridge_constrained.gz", ss = SS, chr = CHR),
        expand("output/{ss}/priors/{ss}_l2-ldsc.{chr}.snpvar_ridge.gz", ss = SS, chr = CHR),
        expand("output/{ss}/polyfun_susie_{LD}_finemap/{ss}_polyfun_susie_all.txt.gz", ss = SS, LD = ["noLD", "withLD"]),
        expand("output/{ss}/polyfun_finemap_{LD}_finemap/{ss}_polyfun_finemap_all.txt.gz", ss = SS, LD = ["noLD", "withLD"]),
        expand("output/{ss}/only_finemap_{LD}_finemap/{ss}_only_finemap_all.txt.gz", ss = SS, LD = ["noLD", "withLD"]),
        expand("output/{ss}/only_susie_{LD}_finemap/{ss}_only_susie_all.txt.gz", ss = SS, LD = ["noLD", "withLD"]),
        expand("output/{ss}/{ss}_{method}_{LD}_vep_output.txt", ss = SS, method = ["only_finemap", "only_susie", "polyfun_susie", "polyfun_finemap"], LD = ["noLD", "withLD"]),


rule munge_polyfun:
    input: lambda wildcards: full_sumstats[wildcards.ss]
    output: "output/{ss}_neff.munged.parquet"
    conda: "envs/polyfun.yml"
    params: sample_size = lambda wildcards: sample_size[wildcards.ss]
    resources:
        mem_mb = 20000,
        lsf_jobname = "munge_polyfun",
        lsf_extra = "-o logs/munge_polyfun.%J.out -e logs/munge_polyfun.%J.err"
    shell:
        """
        python polyfun/munge_polyfun_sumstats.py \
        --sumstats {input} \
        --out {output} \
        --n {params.sample_size} \
        --min-info 0.6 \
        --min-maf 0
        """


rule l2reg_sldsc:
    input:
        gwas = "output/{ss}_neff.munged.parquet"
    output:
        output1 = "output/{ss}/priors/{ss}_l2-ldsc.{chr}.snpvar_ridge_constrained.gz",
        output2 = "output/{ss}/priors/{ss}_l2-ldsc.{chr}.snpvar_ridge.gz"
    params:
        weights = "/weights.UKB.",
        ldscores = "/baselineLF2.2.UKB.",
        prefix = lambda wc: f"output/{wc.ss}/priors/{wc.ss}_l2-ldsc"
    conda: "envs/polyfun.yml"
    resources:
        mem_mb = 170000,
        lsf_jobname = "l2reg_sldsc",
        lsf_extra = "-o logs/l2reg_sldsc.%J.out -e logs/l2reg_sldsc.%J.err"
    shell:
        """
        python polyfun/polyfun.py \
        --compute-h2-L2 \
        --no-partitions \
        --output-prefix {params.prefix} \
        --sumstats {input.gwas} \
        --allow-missing \
        --ref-ld-chr resources/UKBB_priors/hg19_baselineLF2.2.UKB{params.ldscores} \
        --w-ld-chr resources/UKBB_priors/hg19_baselineLF2.2.UKB{params.weights}
        """


rule run_polyfun_susie_noLD:
    input:
        snpvar = lambda wc: f"output/{wc.ss}/priors/{wc.ss}_l2-ldsc.{snp_tables[wc.ss].loc[wc.snp]['chrom_orig']}.snpvar_ridge_constrained.gz"
    output:
        output = "output/{ss}/polyfun_susie_noLD_finemap/{ss}_finemap.{snp}.gz"
    params:
        sample_size_gwas = lambda wc: sample_size[wc.ss],
        chrom = lambda wc: snp_tables[wc.ss].loc[wc.snp]['chrom_orig'],
        start = lambda wc: snp_tables[wc.ss].loc[wc.snp]['range.left'],
        end = lambda wc: snp_tables[wc.ss].loc[wc.snp]['range.right']
    conda: "envs/polyfun.yml"
    resources:
        mem_mb = 32000,
        lsf_jobname = "run_polyfun_susie_noLD",
        lsf_extra = "-o logs/run_polyfun_susie_noLD.%J.out -e logs/run_polyfun_susie_noLD.%J.err"
    shell:
        """
        python polyfun/finemapper.py \
        --sumstats {input.snpvar} \
        --n {params.sample_size_gwas} \
        --chr {params.chrom} \
        --start {params.start} \
        --end {params.end} \
        --method susie \
        --max-num-causal 1 \
        --out {output.output} \
        --allow-missing
        """


rule run_polyfun_susie_withLD:
    input:
        snpvar = lambda wc: f"output/{wc.ss}/priors/{wc.ss}_l2-ldsc.{snp_tables[wc.ss].loc[wc.snp]['chrom_orig']}.snpvar_ridge_constrained.gz"
    output:
        output = "output/{ss}/polyfun_susie_withLD_finemap/{ss}_finemap.{snp}.gz"
    params:
        sample_size_gwas = lambda wc: sample_size[wc.ss],
        chrom = lambda wc: snp_tables[wc.ss].loc[wc.snp]['chrom_orig'],
        start = lambda wc: snp_tables[wc.ss].loc[wc.snp]['range.left'],
        end = lambda wc: snp_tables[wc.ss].loc[wc.snp]['range.right'],
        ld_ranges = lambda wildcards: snp_tables[wildcards.ss].loc[wildcards.snp]['file']
    conda: "envs/polyfun.yml"
    resources:
        mem_mb = 32000,
        lsf_jobname = "run_polyfun_susie_withLD",
        lsf_extra = "-o logs/run_polyfun_susie_withLD.%J.out -e logs/run_polyfun_susie_withLD.%J.err"
    shell:
        """
        python polyfun/finemapper.py \
        --geno resources/genotype_ref_panel/HRC_fromBroad/chr1_22c/pop_EUR/HRC.r1-1.EGA.GRCh37.chr{params.chrom}.impute.plink.EUR \
        --sumstats {input.snpvar} \
        --n {params.sample_size_gwas} \
        --chr {params.chrom} \
        --start {params.start} \
        --end {params.end} \
        --method susie \
        --max-num-causal 5 \
        --out {output.output} \
        --allow-missing
        """


rule merge_finemapping_jobs_polysusie:
    input: 
        lambda wc: expand("output/{ss}/polyfun_susie_{LD}_finemap/{ss}_finemap.{snp}.gz", ss=wc.ss, snp=snp_tables[wc.ss].index.tolist(), LD=wc.LD)
    output: 
        "output/{ss}/polyfun_susie_{LD}_finemap/{ss}_polyfun_susie_all.txt.gz"
    conda: "envs/polyfun.yml"
    resources:
        mem_mb = 8000,
        lsf_jobname = "merge_finemapping_jobs_polysusie",
        lsf_extra = "-o logs/merge_finemapping_jobs_polysusie.%J.out -e logs/merge_finemapping_jobs_polysusie.%J.err"
    shell:
        "cat {input} >> {output}"


rule run_polyfun_finemap_noLD:
    input:
        snpvar = lambda wc: f"output/{wc.ss}/priors/{wc.ss}_l2-ldsc.{snp_tables[wc.ss].loc[wc.snp]['chrom_orig']}.snpvar_ridge_constrained.gz"
    output:
        output = "output/{ss}/polyfun_finemap_noLD_finemap/{ss}_finemap_finemap.{snp}.gz"
    params:
        sample_size_gwas = lambda wc: sample_size[wc.ss],
        chrom = lambda wc: snp_tables[wc.ss].loc[wc.snp]['chrom_orig'],
        start = lambda wc: snp_tables[wc.ss].loc[wc.snp]['range.left'],
        end = lambda wc: snp_tables[wc.ss].loc[wc.snp]['range.right']
    conda: "envs/polyfun.yml"
    resources:
        mem_mb = 32000,
        lsf_jobname = "run_polyfun_finemap_noLD",
        lsf_extra = "-o logs/run_polyfun_finemap_noLD.%J.out -e logs/run_polyfun_finemap_noLD.%J.err"
    shell:
        """
        python polyfun/finemapper.py \
        --sumstats {input.snpvar} \
        --n {params.sample_size_gwas} \
        --chr {params.chrom} \
        --start {params.start} \
        --end {params.end} \
        --method finemap \
        --finemap-exe finemap_v1.4.2_x86_64/finemap_v1.4.2_x86_64 \
        --max-num-causal 1 \
        --out {output.output} \
        --allow-missing
        """


rule run_polyfun_finemap_withLD:
    input:
        snpvar = lambda wc: f"output/{wc.ss}/priors/{wc.ss}_l2-ldsc.{snp_tables[wc.ss].loc[wc.snp]['chrom_orig']}.snpvar_ridge_constrained.gz"
    output:
        output = "output/{ss}/polyfun_finemap_withLD_finemap/{ss}_finemap_finemap.{snp}.gz"
    params:
        sample_size_gwas = lambda wc: sample_size[wc.ss],
        chrom = lambda wc: snp_tables[wc.ss].loc[wc.snp]['chrom_orig'],
        start = lambda wc: snp_tables[wc.ss].loc[wc.snp]['range.left'],
        end = lambda wc: snp_tables[wc.ss].loc[wc.snp]['range.right'],
        ld_ranges = lambda wildcards: snp_tables[wildcards.ss].loc[wildcards.snp]['file']
    conda: "envs/polyfun.yml"
    resources:
        mem_mb = 32000,
        lsf_jobname = "run_polyfun_finemap_withLD",
        lsf_extra = "-o logs/run_polyfun_finemap_withLD.%J.out -e logs/run_polyfun_finemap_withLD.%J.err"
    shell:
        """
        python polyfun/finemapper.py \
        --geno resources/genotype_ref_panel/HRC_fromBroad/chr1_22c/pop_EUR/HRC.r1-1.EGA.GRCh37.chr{params.chrom}.impute.plink.EUR \
        --sumstats {input.snpvar} \
        --n {params.sample_size_gwas} \
        --chr {params.chrom} \
        --start {params.start} \
        --end {params.end} \
        --method finemap \
        --finemap-exe finemap_v1.4.2_x86_64/finemap_v1.4.2_x86_64 \
        --max-num-causal 5 \
        --out {output.output} \
        --allow-missing
        """


rule merge_finemapping_jobs_polyfinemap:
    input: 
        lambda wc: expand("output/{ss}/polyfun_finemap_{LD}_finemap/{ss}_finemap_finemap.{snp}.gz", ss=wc.ss, snp=snp_tables[wc.ss].index.tolist(), LD=wc.LD)
    output: 
        "output/{ss}/polyfun_finemap_{LD}_finemap/{ss}_polyfun_finemap_all.txt.gz"
    conda: "envs/polyfun.yml"
    resources:
        mem_mb = 8000,
        lsf_jobname = "merge_finemapping_jobs_polyfinemap",
        lsf_extra = "-o logs/merge_finemapping_jobs_polyfinemap.%J.out -e logs/merge_finemapping_jobs_polyfinemap.%J.err"
    shell:
        "cat {input} >> {output}"


rule run_only_finemap_noLD:
    input:
        snpvar = lambda wc: f"output/{wc.ss}/priors/{wc.ss}_l2-ldsc.{snp_tables[wc.ss].loc[wc.snp]['chrom_orig']}.snpvar_ridge_constrained.gz"
    output:
        output = "output/{ss}/only_finemap_noLD_finemap/{ss}_only_finemap.{snp}.gz"
    params:
        sample_size_gwas = lambda wc: sample_size[wc.ss],
        chrom = lambda wc: snp_tables[wc.ss].loc[wc.snp]['chrom_orig'],
        start = lambda wc: snp_tables[wc.ss].loc[wc.snp]['range.left'],
        end = lambda wc: snp_tables[wc.ss].loc[wc.snp]['range.right']
    conda: "envs/polyfun.yml"
    resources:
        mem_mb = 32000,
        lsf_jobname = "run_only_finemap_noLD",
        lsf_extra = "-o logs/run_only_finemap_noLD.%J.out -e logs/run_only_finemap_noLD.%J.err"
    shell:
        """
        python polyfun/finemapper.py \
        --sumstats {input.snpvar} \
        --n {params.sample_size_gwas} \
        --chr {params.chrom} \
        --start {params.start} \
        --end {params.end} \
        --method finemap \
        --finemap-exe finemap_v1.4.2_x86_64/finemap_v1.4.2_x86_64 \
        --non-funct \
        --max-num-causal 1 \
        --out {output.output} \
        --allow-missing
        """


rule run_only_finemap_withLD:
    input:
        snpvar = lambda wc: f"output/{wc.ss}/priors/{wc.ss}_l2-ldsc.{snp_tables[wc.ss].loc[wc.snp]['chrom_orig']}.snpvar_ridge_constrained.gz"
    output:
        output = "output/{ss}/only_finemap_withLD_finemap/{ss}_only_finemap.{snp}.gz"
    params:
        sample_size_gwas = lambda wc: sample_size[wc.ss],
        chrom = lambda wc: snp_tables[wc.ss].loc[wc.snp]['chrom_orig'],
        start = lambda wc: snp_tables[wc.ss].loc[wc.snp]['range.left'],
        end = lambda wc: snp_tables[wc.ss].loc[wc.snp]['range.right'],
        ld_ranges = lambda wildcards: snp_tables[wildcards.ss].loc[wildcards.snp]['file']
    conda: "envs/polyfun.yml"
    resources:
        mem_mb = 32000,
        lsf_jobname = "run_only_finemap_withLD",
        lsf_extra = "-o logs/run_only_finemap_withLD.%J.out -e logs/run_only_finemap_withLD.%J.err"
    shell:
        """
        python polyfun/finemapper.py \
        --geno resources/genotype_ref_panel/HRC_fromBroad/chr1_22c/pop_EUR/HRC.r1-1.EGA.GRCh37.chr{params.chrom}.impute.plink.EUR \
        --sumstats {input.snpvar} \
        --n {params.sample_size_gwas} \
        --chr {params.chrom} \
        --start {params.start} \
        --end {params.end} \
        --method finemap \
        --finemap-exe finemap_v1.4.2_x86_64/finemap_v1.4.2_x86_64 \
        --non-funct \
        --max-num-causal 5 \
        --out {output.output} \
        --allow-missing
        """


rule merge_finemapping_jobs_onlyfinemap:
    input: 
        lambda wc: expand("output/{ss}/only_finemap_{LD}_finemap/{ss}_only_finemap.{snp}.gz", ss=wc.ss, snp=snp_tables[wc.ss].index.tolist(), LD=wc.LD)
    output: 
        "output/{ss}/only_finemap_{LD}_finemap/{ss}_only_finemap_all.txt.gz"
    conda: "envs/polyfun.yml"
    resources:
        mem_mb = 8000,
        lsf_jobname = "merge_finemapping_jobs_onlyfinemap",
        lsf_extra = "-o logs/merge_finemapping_jobs_onlyfinemap.%J.out -e logs/merge_finemapping_jobs_onlyfinemap.%J.err"
    shell:
        "cat {input} >> {output}"


rule run_only_susie_noLD:
    input:
        snpvar = lambda wc: f"output/{wc.ss}/priors/{wc.ss}_l2-ldsc.{snp_tables[wc.ss].loc[wc.snp]['chrom_orig']}.snpvar_ridge_constrained.gz"
    output:
        output = "output/{ss}/only_susie_noLD_finemap/{ss}_only_susie.{snp}.gz"
    params:
        sample_size_gwas = lambda wc: sample_size[wc.ss],
        chrom = lambda wc: snp_tables[wc.ss].loc[wc.snp]['chrom_orig'],
        start = lambda wc: snp_tables[wc.ss].loc[wc.snp]['range.left'],
        end = lambda wc: snp_tables[wc.ss].loc[wc.snp]['range.right']
    conda: "envs/polyfun.yml"
    resources:
        mem_mb = 32000,
        lsf_jobname = "run_only_susie_noLD",
        lsf_extra = "-o logs/run_only_susie_noLD.%J.out -e logs/run_only_susie_noLD.%J.err"
    shell:
        """
        python polyfun/finemapper.py \
        --sumstats {input.snpvar} \
        --n {params.sample_size_gwas} \
        --chr {params.chrom} \
        --start {params.start} \
        --end {params.end} \
        --method susie \
        --non-funct \
        --max-num-causal 1 \
        --out {output.output} \
        --allow-missing
        """


rule run_only_susie_withLD:
    input:
        snpvar = lambda wc: f"output/{wc.ss}/priors/{wc.ss}_l2-ldsc.{snp_tables[wc.ss].loc[wc.snp]['chrom_orig']}.snpvar_ridge_constrained.gz"
    output:
        output = "output/{ss}/only_susie_withLD_finemap/{ss}_only_susie.{snp}.gz"
    params:
        sample_size_gwas = lambda wc: sample_size[wc.ss],
        chrom = lambda wc: snp_tables[wc.ss].loc[wc.snp]['chrom_orig'],
        start = lambda wc: snp_tables[wc.ss].loc[wc.snp]['range.left'],
        end = lambda wc: snp_tables[wc.ss].loc[wc.snp]['range.right'],
        ld_ranges = lambda wildcards: snp_tables[wildcards.ss].loc[wildcards.snp]['file']
    conda: "envs/polyfun.yml"
    resources:
        mem_mb = 32000,
        lsf_jobname = "run_only_susie_withLD",
        lsf_extra = "-o logs/run_only_susie_withLD.%J.out -e logs/run_only_susie_withLD.%J.err"
    shell:
        """
        python polyfun/finemapper.py \
        --geno resources/genotype_ref_panel/HRC_fromBroad/chr1_22c/pop_EUR/HRC.r1-1.EGA.GRCh37.chr{params.chrom}.impute.plink.EUR \
        --sumstats {input.snpvar} \
        --n {params.sample_size_gwas} \
        --chr {params.chrom} \
        --start {params.start} \
        --end {params.end} \
        --method susie \
        --non-funct \
        --max-num-causal 5 \
        --out {output.output} \
        --allow-missing
        """


rule merge_finemapping_jobs_onlysusie:
    input: 
        lambda wc: expand("output/{ss}/only_susie_{LD}_finemap/{ss}_only_susie.{snp}.gz", ss=wc.ss, snp=snp_tables[wc.ss].index.tolist(), LD=wc.LD)
    output: 
        "output/{ss}/only_susie_{LD}_finemap/{ss}_only_susie_all.txt.gz"
    conda: "envs/polyfun.yml"
    resources:
        mem_mb = 8000,
        lsf_jobname = "merge_finemapping_jobs_onlysusie",
        lsf_extra = "-o logs/merge_finemapping_jobs_onlysusie.%J.out -e logs/merge_finemapping_jobs_onlysusie.%J.err"
    shell:  
        "cat {input} >> {output}"


rule filter_for_vep:
    input:
        "output/{ss}/{method}_{LD}_finemap/{ss}_{method}_all.txt.gz"
    output:
        "output/{ss}/{method}_{LD}_finemap/{ss}_{method}_filtered.txt.gz"
    conda: "envs/polyfun.yml"
    resources:
        mem_mb = 16000,
        lsf_jobname = "filter_for_vep",
        lsf_extra = "-o logs/filter_for_vep.%J.out -e logs/filter_for_vep.%J.err"
    run:
        import pandas as pd
        import gzip
        
        with gzip.open(input[0], 'rt') as f:
            df = pd.read_csv(f, sep = '\t')
        
        df['PIP'] = pd.to_numeric(df['PIP'], errors = 'coerce')
        df = df.dropna(subset = ['PIP'])
        
        if 'susie' in wildcards.method:
            filtered_df = df[(df['PIP'] > 0.1)]
        elif 'finemap' in wildcards.method:
            df['CREDIBLE_SET'] = pd.to_numeric(df['CREDIBLE_SET'], errors = 'coerce')
            df = df.dropna(subset = ['CREDIBLE_SET'])
            filtered_df = df[(df['PIP'] > 0.1) & (df['CREDIBLE_SET'] != 0)]

        with gzip.open(output[0], 'wt') as f:
            filtered_df.to_csv(f, sep = '\t', index = False)


rule prepare_vep_input:
    input:
        "output/{ss}/{method}_{LD}_finemap/{ss}_{method}_filtered.txt.gz"
    output:
        "output/{ss}/{method}_{LD}_finemap/{ss}_{method}_{LD}_vep_input.txt"
    conda: "envs/polyfun.yml"
    resources:
        mem_mb = 16000,
        lsf_jobname = "prepare_vep_input",
        lsf_extra = "-o logs/prepare_vep_input.%J.out -e logs/prepare_vep_input.%J.err"
    run:
        import pandas as pd
        import gzip
        
        with gzip.open(input[0], 'rt') as f:
            df = pd.read_csv(f, sep = '\t')
        
        unique_variants = set()
        vep_input = []
        
        for _, row in df.iterrows():
            try:
                int(row['BP'])
            except (ValueError, TypeError):
                continue

            variant_key = f"{row['CHR']}:{row['BP']}:{row['A2']}:{row['A1']}"
            
            if variant_key not in unique_variants:
                unique_variants.add(variant_key)
                vep_line = f"{row['CHR']} {row['BP']} {row['BP']} {row['A2']}/{row['A1']} +"
                vep_input.append(vep_line)
                
        with open(output[0], 'w') as f:
            for line in vep_input:
                f.write(line + '\n')


rule run_vep_annotation:
    input:
        input = "output/{ss}/{method}_{LD}_finemap/{ss}_{method}_{LD}_vep_input.txt"
    output:
        output = "output/{ss}/{ss}_{method}_{LD}_vep_output.txt"
    conda: "envs/vep.yml"
    resources:
        mem_mb = 16000,
        lsf_jobname = "run_vep_annotation",
        lsf_extra = "-o logs/run_vep_annotation.%J.out -e logs/run_vep_annotation.%J.err"
    shell:
        """
        module load vep/112
        
        vep -i {input.input} \
            -o {output.output} \
            --dir_cache vep/112/cache \
            --offline \
            --assembly GRCh37 \
            --symbol
        """

